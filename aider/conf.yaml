# complete sample file: https://raw.githubusercontent.com/Aider-AI/aider/refs/heads/main/aider/website/assets/sample.aider.conf.yml
# ------------------------------------------------
# HISTORY OF OPENROUTER MODELS USED:
# ------------------------------------------------
# openrouter/anthropic/claude-haiku-4.5
# openrouter/anthropic/claude-sonnet-4
# openrouter/anthropic/claude-sonnet-4.5
# openrouter/google/gemini-2.5-flash
# openrouter/x-ai/grok-code-fast-1
# openrouter/z-ai/glm-4.5
# openrouter/qwen/qwen3-coder
# openrouter/google/gemini-2.5-pro
# openrouter/google/gemini-3-pro-preview
# openrouter/deepseek/deepseek-v3.2-exp (164K context window, HAS stream cancellation, reasoning and caching)
# @preset/deepseek-3-2-speciale-fast - preset for openrouter/deepseek/deepseek-v3.2-speciale (164K context window, NO caching and tools)
# openrouter/google/gemini-2.5-flash-lite (1.05M context window, has reasoning and caching but NO stream cancellation)
# openrouter/mistralai/devstral-2512:free (free - 0 tokens, 262K context window. NO stream cancellation, reasoning or caching)
# openrouter/z-ai/glm-4.7
# openrouter/minimax/minimax-m2.1 (197k context window, reasoning, has stream cancellation but no caching)
# openrouter/google/gemini-3-flash-preview (1.05M context window, reasoning, and NO stream cancellation, but has caching.)
# @preset/glm-4-7-flash-fast-providers - preset for openrouter/z-ai/glm-4.7-flash (200k context window, reasoning, HAS stream cancellation and caching)
# openrouter/moonshotai/kimi-k2.5
# ---------------------------------------------
# openrouter trending models pages:
# https://openrouter.ai/rankings?category=programming#programming-languages
#----------------------------------------------
# presets can help changing a models provider (e.g. to faster ones), and other configs also:
#   about................: https://openrouter.ai/docs/guides/features/presets
#   my account presets...: https://openrouter.ai/settings/presets
#----------------------------------------------

editor: nvim
auto-commits: false
multiline: true
vim: true

# Appearance
dark-mode: true
code-theme: solarized-dark

# MAIN / ARCHITECT MODEL GUIDELINES
# - Responsible for understanding requirements, reasoning through the codebase, and formulating coding plans
# - Needs advanced reasoning/thinking capabilities
# - Must deduce implicit requirements and navigate complex dependencies
# - Speed is secondary; intelligence and reasoning depth are primary
# - Allowed to use full context window and reasoning budget (don't artificially limit)
model: openrouter/moonshotai/kimi-k2.5
auto-accept-architect: false

# EDITOR MODEL GUIDELINES
# - Responsible for taking the Architect's plan and applying it to files via diffs
# - Needs to be fast, cheap, and strictly obedient to diff format rules
# - Should have large context window to read entire file contents without truncation
# - Will be called repeatedly to re-read files and apply patches, so cost-per-token matters significantly
# - Speed of inference directly impacts user experience (waiting for code changes)
weak-model: openrouter/mistralai/devstral-2512
editor-model: openrouter/mistralai/devstral-2512

# History and caching
cache-prompts: true
cache-keepalive-pings: 3

# History files
# input-history-file: .aider.input.history
# chat-history-file: .aider.chat.history.md
# restore-chat-history: false
# llm-history-file: .aider.llm.history

# -------------------------------------------------------------------------------------------------
# Load commands on startup
# -------------------------------------------------------------------------------------------------
# - Corresponds to --load LOAD_FILE, which runs aider /commands from a file on startup
#   (for example /add, /read, /code etc.), acting like a startup script.
# - Use load: .aider.load.commands if you want a deterministic startup routine (e.g.,
#   autoâ€‘/read a conventions file with commands), and keep /read in the commands themselves.
# -------------------------------------------------------------------------------------------------
# load: .aider.load.commands

# Notifications (tmux)
notifications: true
notifications-command: "tmux display-message 'aider: Your inquiry response is ready, Captain.'"
