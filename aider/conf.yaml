# complete sample file: https://raw.githubusercontent.com/Aider-AI/aider/refs/heads/main/aider/website/assets/sample.aider.conf.yml
# ------------------------------------------------
# HISTORY OF OPENROUTER MODELS USED:
# ------------------------------------------------
# openrouter/anthropic/claude-haiku-4.5
# openrouter/anthropic/claude-sonnet-4
# openrouter/anthropic/claude-sonnet-4.5
# openrouter/google/gemini-2.5-flash
# openrouter/google/gemini-3-pro-preview
# openrouter/x-ai/grok-code-fast-1
# openrouter/z-ai/glm-4.5
# openrouter/qwen/qwen3-coder
# openrouter/google/gemini-2.5-pro
# openrouter/deepseek/deepseek-v3.2-exp (has caching according to https://openrouter.ai/compare/deepseek/deepseek-v3.2-exp)
# openrouter/deepseek/deepseek-v3.2-speciale (does not have caching but was created Dec 1st 2025)
# openrouter/x-ai/grok-4.1-fast (2M context window, has reasoning and caching) -- VERY BAD, DO NOT USE
# openrouter/google/gemini-2.5-flash-lite (1.05M context window, has reasoning and caching)
# openrouter/deepseek/deepseek-v3.2-exp (164K context window, HAS stream cancellation, reasoning and caching)
# openrouter/deepseek/deepseek-v3.2-speciale (164K context window, NO caching and tools)
# openrouter/google/gemini-2.5-flash-lite (1.05M context window, NO stream cancellation)
# openrouter/mistralai/devstral-2512:free (free - 0 tokens, 262K context window. NO stream cancellation, reasoning or caching)
# ---------------------------------------------
# openrouter trending models pages:
# https://openrouter.ai/rankings?category=programming#programming-languages
#-----------------------------------------
editor: nvim
auto-commits: false
multiline: true
vim: true

# Appearance
dark-mode: true
code-theme: solarized-dark

# - Below was configured with the help of perplexity:
#   https://www.perplexity.ai/search/i-have-in-my-hands-this-page-w-aYVHZQ2dQ8mvYQhD5UxEPg
#
#   I must use this chat as a reference if/when I need to update any of the models.
#

# Main model (you will choose one of these per profile)
# model: openrouter/deepseek/deepseek-v3.2-speciale
model: openrouter/google/gemini-2.5-flash-lite

# Reasoning-related
reasoning-effort: low
thinking-tokens: 0

# Secondary models
weak-model: openrouter/deepseek/deepseek-v3.2-exp
editor-model: openrouter/deepseek/deepseek-v3.2-exp

# History and caching
max-chat-history-tokens: 8000
cache-prompts: true
cache-keepalive-pings: 3

# History files
# input-history-file: .aider.input.history
# chat-history-file: .aider.chat.history.md
# restore-chat-history: false
# llm-history-file: .aider.llm.history

# -------------------------------------------------------------------------------------------------
# Load commands on startup
# -------------------------------------------------------------------------------------------------
# - Corresponds to --load LOAD_FILE, which runs aider /commands from a file on startup
#   (for example /add, /read, /code etc.), acting like a startup script.
# - Use load: .aider.load.commands if you want a deterministic startup routine (e.g.,
#   autoâ€‘/read a conventions file with commands), and keep /read in the commands themselves.
# -------------------------------------------------------------------------------------------------
# load: .aider.load.commands

# Notifications (tmux)
notifications: true
notifications-command: "tmux display-message 'aider: Your inquiry response is ready, Captain.'"
